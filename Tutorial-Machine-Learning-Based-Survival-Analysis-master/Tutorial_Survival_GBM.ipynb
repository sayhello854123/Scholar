{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Survival Analysis: Based on Gradient Boosting Machine(GBM)\n",
    "\n",
    "The tutorial give typical workflow of Gradient Boosting Desicion Tree-based survival analysis including data-preprocessing, model selection and traning&validation, uses R package `gbm`.\n",
    "\n",
    "Formally, it can be listed by:\n",
    "1. Data Preprocessing\n",
    "  - convert variables\n",
    "  - load training and test set\n",
    "2. Model Selection\n",
    "  - cross validation\n",
    "  - tune parameters\n",
    "3. Traning&Validation\n",
    "  - train gbm model\n",
    "  - measure CI on testset\n",
    "  - survival rates on time of interest\n",
    "  \n",
    "The best suggestion about usage of `gbm` is official documentation named **\"Generalized Boosted Models:A guide to the gbm package\"**. Here, I summary some points related to usage of the package and SA, and disscussion of options to gbm that most users will need to change or tune.\n",
    "\n",
    "### 1. Loss Function\n",
    "\n",
    "`distribution` is corresponding to loss function and application. Here, the option `coxph` indicating SA should be selected.\n",
    "\n",
    "### 2. Model Fitting\n",
    "\n",
    "`shrinkage` and `n.trees` are mostly related to performance, so those should be tuned carefully.\n",
    "\n",
    "As recommended by author of `gbm`, it is generally the case that for small shrinkage parameters, 0.001 for example.\n",
    ">  My rule of thumb is to set shrinkage as small as possible while still being able to fit the model in a reasonable amount of time and storage. I usually aim for 3,000 to 10,000 iterations with shrinkage rates between 0.01 and 0.001.\n",
    "\n",
    "### 3. The Optimal Number of Iterations\n",
    "\n",
    "`gbm` offers three methods for estimating the optimal number of iterations after the gbm model has been fit, an independent test set (`test`), out-of-bag estimation (`OOB`), and v-fold cross validation (`cv`). The function `gbm.perf` computes the iteration estimate.\n",
    "\n",
    "Among these methods for estimating `n.trees`, **V-Fold Cross Validation** is the best choice.\n",
    "> My recommendation is to use 5- or 10-fold cross validation if you can afford the computing time. Otherwise you may choose among the other options, knowing that OOB is conservative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step0 - Load library and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'gbm' was built under R version 3.5.1\"Loaded gbm 2.1.4\n"
     ]
    }
   ],
   "source": [
    "library('survival')\n",
    "library('gbm')\n",
    "# set random state\n",
    "set.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 137 \n",
      "Columns of dataset: trt celltype time status karno diagtime age prior \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>trt</th><th scope=col>celltype</th><th scope=col>time</th><th scope=col>status</th><th scope=col>karno</th><th scope=col>diagtime</th><th scope=col>age</th><th scope=col>prior</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1  </td><td>1  </td><td> 72</td><td>1  </td><td>60 </td><td> 7 </td><td>69 </td><td> 0 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>411</td><td>1  </td><td>70 </td><td> 5 </td><td>64 </td><td>10 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>228</td><td>1  </td><td>60 </td><td> 3 </td><td>38 </td><td> 0 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>126</td><td>1  </td><td>60 </td><td> 9 </td><td>63 </td><td>10 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>118</td><td>1  </td><td>70 </td><td>11 </td><td>65 </td><td>10 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " trt & celltype & time & status & karno & diagtime & age & prior\\\\\n",
       "\\hline\n",
       "\t 1   & 1   &  72 & 1   & 60  &  7  & 69  &  0 \\\\\n",
       "\t 1   & 1   & 411 & 1   & 70  &  5  & 64  & 10 \\\\\n",
       "\t 1   & 1   & 228 & 1   & 60  &  3  & 38  &  0 \\\\\n",
       "\t 1   & 1   & 126 & 1   & 60  &  9  & 63  & 10 \\\\\n",
       "\t 1   & 1   & 118 & 1   & 70  & 11  & 65  & 10 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "trt | celltype | time | status | karno | diagtime | age | prior | \n",
       "|---|---|---|---|---|\n",
       "| 1   | 1   |  72 | 1   | 60  |  7  | 69  |  0  | \n",
       "| 1   | 1   | 411 | 1   | 70  |  5  | 64  | 10  | \n",
       "| 1   | 1   | 228 | 1   | 60  |  3  | 38  |  0  | \n",
       "| 1   | 1   | 126 | 1   | 60  |  9  | 63  | 10  | \n",
       "| 1   | 1   | 118 | 1   | 70  | 11  | 65  | 10  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  trt celltype time status karno diagtime age prior\n",
       "1 1   1         72  1      60     7       69   0   \n",
       "2 1   1        411  1      70     5       64  10   \n",
       "3 1   1        228  1      60     3       38   0   \n",
       "4 1   1        126  1      60     9       63  10   \n",
       "5 1   1        118  1      70    11       65  10   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(veteran, package = \"randomForestSRC\")\n",
    "cat(\"Number of samples:\", nrow(veteran), \"\\n\")\n",
    "cat(\"Columns of dataset:\", colnames(veteran), \"\\n\")\n",
    "veteran[c(1:5), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample the data and create a training subset.\n",
    "train <- sample(1:nrow(veteran), round(nrow(veteran) * 0.80))\n",
    "data_train <- veteran[train, ]\n",
    "data_test <- veteran[-train, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 - Model Selection\n",
    "\n",
    "The hyperparameters should be tuned as follows:\n",
    "- `shrinkage` (i.e., learning_rate)\n",
    "- `n.trees` (total number of trees to fit)\n",
    "- `interaction.depth` (maximum depth of each tree)\n",
    "- `n.minobsinnode` (minimum number of observations in the terminal nodes of the trees)\n",
    "\n",
    "Optional Reading: You can try to search the best hyperparameters' estimation by using python package `hyperopt`.\n",
    "\n",
    "By the means of described, repeated 4-fold cross validation on training set for 3 times is used, results of searching are:\n",
    "- \"n.trees\": 3000\n",
    "- \"shrinkage\": 0.005\n",
    "- \"interaction.depth\": 2\n",
    "- \"n.minobsinnode\": 5\n",
    "- ci=0.701183(average on repeated 4-fold cross validation for 3 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 - Model Training & Evaluation\n",
    "\n",
    "We will pass arguments to object `gbm` for training robust model after completing hyperparameters tuning in step2, and then validate our fitted model using test set.\n",
    "\n",
    "Here, evaluation and more in this section includes:\n",
    "\n",
    "- calculating CI metrics\n",
    "- calculating survival function on specified time\n",
    "- saving result as file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 - Model Training & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] 6.272987 6.272907 6.272681 6.272755 6.272670 6.272456 6.272487 6.272337\n",
      "  [9] 6.272159 6.272079 6.272006 6.271792 6.271141 6.270999 6.270618 6.270300\n",
      " [17] 6.270110 6.270016 6.269998 6.270000 6.269819 6.269646 6.269598 6.269504\n",
      " [25] 6.269357 6.269255 6.269225 6.269045 6.268980 6.268933 6.268696 6.268707\n",
      " [33] 6.268544 6.268420 6.268395 6.268200 6.268113 6.267884 6.267657 6.267704\n",
      " [41] 6.267584 6.267579 6.267789 6.267881 6.267847 6.267803 6.267657 6.267598\n",
      " [49] 6.267828 6.267691 6.267558 6.267598 6.267417 6.267321 6.267459 6.267548\n",
      " [57] 6.267511 6.267446 6.267350 6.267368 6.267399 6.267221 6.266798 6.266589\n",
      " [65] 6.266697 6.266545 6.266681 6.266773 6.266645 6.266570 6.266458 6.266259\n",
      " [73] 6.266186 6.266106 6.266010 6.266032 6.266148 6.266037 6.265965 6.265864\n",
      " [81] 6.265875 6.265634 6.265440 6.265422 6.265410 6.265237 6.265109 6.264828\n",
      " [89] 6.264833 6.264716 6.264682 6.264463 6.264373 6.264265 6.264142 6.264086\n",
      " [97] 6.263929 6.263762 6.263183 6.262952\n"
     ]
    }
   ],
   "source": [
    "set.seed(2891)\n",
    "# using training set fits gbm model\n",
    "model <- gbm(Surv(time, status) ~ .,\n",
    "             distribution='coxph',\n",
    "             data=data_train,\n",
    "             n.trees=3000,\n",
    "             shrinkage=0.005,\n",
    "             interaction.depth=2,\n",
    "             n.minobsinnode=5,\n",
    "             cv.folds=4)\n",
    "# values of loss function on training set for each tree\n",
    "print(model$train.error[2901:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using function `gbm.perf` to get optimal number of iterations and plotting the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAAP8A/wBNTU1o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\nRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best.iter <- gbm.perf(model, plot.it = TRUE, method = 'cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return a vector of prediction on n.trees indicting log hazard scale.f(x)\n",
    "pred.train <- predict(model, data_train, n.trees = best.iter)\n",
    "pred.test <- predict(model, data_test, n.trees = best.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - CI (concordance index)\n",
    "We can get $\\text{CI}$(concordance index) by function `rcorr.cens` from package `Hmisc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>C Index</dt>\n",
       "\t\t<dd>0.780155642023346</dd>\n",
       "\t<dt>Dxy</dt>\n",
       "\t\t<dd>0.560311284046693</dd>\n",
       "\t<dt>S.D.</dt>\n",
       "\t\t<dd>0.0483528792432884</dd>\n",
       "\t<dt>n</dt>\n",
       "\t\t<dd>110</dd>\n",
       "\t<dt>missing</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>uncensored</dt>\n",
       "\t\t<dd>102</dd>\n",
       "\t<dt>Relevant Pairs</dt>\n",
       "\t\t<dd>11308</dd>\n",
       "\t<dt>Concordant</dt>\n",
       "\t\t<dd>8822</dd>\n",
       "\t<dt>Uncertain</dt>\n",
       "\t\t<dd>626</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[C Index] 0.780155642023346\n",
       "\\item[Dxy] 0.560311284046693\n",
       "\\item[S.D.] 0.0483528792432884\n",
       "\\item[n] 110\n",
       "\\item[missing] 0\n",
       "\\item[uncensored] 102\n",
       "\\item[Relevant Pairs] 11308\n",
       "\\item[Concordant] 8822\n",
       "\\item[Uncertain] 626\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "C Index\n",
       ":   0.780155642023346Dxy\n",
       ":   0.560311284046693S.D.\n",
       ":   0.0483528792432884n\n",
       ":   110missing\n",
       ":   0uncensored\n",
       ":   102Relevant Pairs\n",
       ":   11308Concordant\n",
       ":   8822Uncertain\n",
       ":   626\n",
       "\n"
      ],
      "text/plain": [
       "       C Index            Dxy           S.D.              n        missing \n",
       "  7.801556e-01   5.603113e-01   4.835288e-02   1.100000e+02   0.000000e+00 \n",
       "    uncensored Relevant Pairs     Concordant      Uncertain \n",
       "  1.020000e+02   1.130800e+04   8.822000e+03   6.260000e+02 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hmisc::rcorr.cens(-pred.train, Surv(data_train$time, data_train$status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>C Index</dt>\n",
       "\t\t<dd>0.688622754491018</dd>\n",
       "\t<dt>Dxy</dt>\n",
       "\t\t<dd>0.377245508982036</dd>\n",
       "\t<dt>S.D.</dt>\n",
       "\t\t<dd>0.143360961032101</dd>\n",
       "\t<dt>n</dt>\n",
       "\t\t<dd>27</dd>\n",
       "\t<dt>missing</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>uncensored</dt>\n",
       "\t\t<dd>26</dd>\n",
       "\t<dt>Relevant Pairs</dt>\n",
       "\t\t<dd>668</dd>\n",
       "\t<dt>Concordant</dt>\n",
       "\t\t<dd>460</dd>\n",
       "\t<dt>Uncertain</dt>\n",
       "\t\t<dd>32</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[C Index] 0.688622754491018\n",
       "\\item[Dxy] 0.377245508982036\n",
       "\\item[S.D.] 0.143360961032101\n",
       "\\item[n] 27\n",
       "\\item[missing] 0\n",
       "\\item[uncensored] 26\n",
       "\\item[Relevant Pairs] 668\n",
       "\\item[Concordant] 460\n",
       "\\item[Uncertain] 32\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "C Index\n",
       ":   0.688622754491018Dxy\n",
       ":   0.377245508982036S.D.\n",
       ":   0.143360961032101n\n",
       ":   27missing\n",
       ":   0uncensored\n",
       ":   26Relevant Pairs\n",
       ":   668Concordant\n",
       ":   460Uncertain\n",
       ":   32\n",
       "\n"
      ],
      "text/plain": [
       "       C Index            Dxy           S.D.              n        missing \n",
       "     0.6886228      0.3772455      0.1433610     27.0000000      0.0000000 \n",
       "    uncensored Relevant Pairs     Concordant      Uncertain \n",
       "    26.0000000    668.0000000    460.0000000     32.0000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hmisc::rcorr.cens(-pred.test, Surv(data_test$time, data_test$status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 - Survival function\n",
    "\n",
    "`gbm` offers method `basehaz.gbm` to estimate the cumulative baseline hazard function $\\int_0^{t}\\lambda(z)dz$. Since survival function can be estimated by:\n",
    "$$\n",
    "s(t|X)=exp{\\{-\\ e^{f(X)}\\int_0^{t}\\lambda(z)dz\\}}\n",
    "$$\n",
    "\n",
    "$f(X)$ is prediction of `gbm`, which is equal to log-hazard proportion.\n",
    "So we can get survival function of individuals easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sepecify time of interest\n",
    "time.interest <- sort(unique(data_train$time[data_train$status==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate the cumulative baseline hazard function using training data\n",
    "basehaz.cum <- basehaz.gbm(data_train$time, data_train$status, pred.train, t.eval = time.interest, cumulative = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For individual $i$ in test set, estimation of survival function is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surf.i <- exp(-exp(pred.test[1])*basehaz.cum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 9.927248e-01 9.890281e-01 9.852382e-01 9.736998e-01 9.575063e-01\n",
      " [6] 9.490337e-01 9.446703e-01 9.403137e-01 9.315803e-01 9.270761e-01\n",
      "[11] 9.224916e-01 9.085303e-01 9.034015e-01 8.930300e-01 8.875027e-01\n",
      "[16] 8.763125e-01 8.647355e-01 8.585433e-01 8.523026e-01 8.394247e-01\n",
      "[21] 8.264848e-01 8.199323e-01 8.132473e-01 8.063389e-01 7.993841e-01\n",
      "[26] 7.924367e-01 7.854976e-01 7.783247e-01 7.706500e-01 7.467482e-01\n",
      "[31] 7.294782e-01 7.205871e-01 7.028921e-01 6.939001e-01 6.848827e-01\n",
      "[36] 6.752722e-01 6.655636e-01 6.555930e-01 6.354847e-01 6.245106e-01\n",
      "[41] 6.131282e-01 6.016796e-01 5.898952e-01 5.779547e-01 5.529901e-01\n",
      "[46] 5.398873e-01 5.262693e-01 5.126514e-01 4.991587e-01 4.728259e-01\n",
      "[51] 4.574719e-01 4.421798e-01 4.268952e-01 4.114664e-01 3.957659e-01\n",
      "[56] 3.802090e-01 3.633897e-01 3.457641e-01 3.278898e-01 3.100254e-01\n",
      "[61] 2.918461e-01 2.727655e-01 2.536745e-01 2.347807e-01 2.160340e-01\n",
      "[66] 1.962410e-01 1.763388e-01 1.569783e-01 1.374634e-01 1.180111e-01\n",
      "[71] 1.006372e-01 8.212400e-02 6.361489e-02 4.769086e-02 3.208629e-02\n",
      "[76] 2.016026e-02 1.098290e-02 5.035892e-03 1.230712e-03 2.580346e-05\n"
     ]
    }
   ],
   "source": [
    "print(surf.i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation of survival rate of all at specified time is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Rate of all at time 15 \n",
      " [1] 0.9270761 0.9502494 0.8208986 0.8573067 0.9199247 0.9378880 0.6987562\n",
      " [8] 0.9146517 0.8771222 0.9314684 0.9183110 0.8063917 0.9184431 0.9596170\n",
      "[15] 0.9741025 0.9226616 0.5394012 0.6959224 0.8785593 0.9386735 0.9117690\n",
      "[22] 0.9385850 0.6396585 0.8981364 0.9315653 0.9039892 0.9397032\n"
     ]
    }
   ],
   "source": [
    "specif.time <- time.interest[10]\n",
    "cat(\"Survival Rate of all at time\", specif.time, \"\\n\")\n",
    "surv.rate <- exp(-exp(pred.test)*basehaz.cum[10])\n",
    "print(surv.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - Saving as file\n",
    "\n",
    "Here, we concate test data and prediction, survival rate, and then convert it to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_test <- data_test\n",
    "# predicted outcome for test set\n",
    "res_test$pred <- pred.test\n",
    "res_test$survival_rate <- surv.rate\n",
    "# Save data\n",
    "write.csv(res_test, file = \"result_gbm.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
