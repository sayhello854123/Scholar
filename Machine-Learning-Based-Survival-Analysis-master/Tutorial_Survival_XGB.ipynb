{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival Analysis: Based on eXtreme Gradient Boosting(XGB)\n",
    "\n",
    "The tutorial give typical workflow of eXtreme Gradient Boosting-based survival analysis including data-preprocessing, model selection and traning&validation, uses **R package** `xgboost`.\n",
    "\n",
    "Formally, it can be listed by:\n",
    "1. Data Preprocessing\n",
    "  - convert variables\n",
    "  - load training and test set\n",
    "2. Model Selection\n",
    "  - cross validation\n",
    "  - tune parameters\n",
    "3. Traning&Validation\n",
    "  - train gbm model\n",
    "  - measure CI on testset\n",
    "  - survival rates on time of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept and Related\n",
    "\n",
    "#### Concept of coxph\n",
    "Under assumption of cox proportional hazard model, there is:\n",
    "$$h(t|x) = h_0(t) \\cdot e^{f(x)}$$\n",
    "$f(x)$ is called **Hazard Ratio**.\n",
    "\n",
    "Given the observation $\\{(X_i,T_i,E_i)|i=1,\\dots ,n \\}$, the log partial likelihood function is:\n",
    "$$\n",
    "\\mathcal L=-\\sum_{i\\ :\\ E_i=1}\\bigl(f(x_i)-log\\sum_{j\\in \\mathcal R(i)}e^{f(x_j)}\\bigr) \\\\\n",
    "\\mathcal R(i)=\\{j|T_j\\ge T_i\\}\n",
    "$$\n",
    "If there is ties at time of death, the corresponding log partial likelihood function is:\n",
    "$$\n",
    "\\mathcal L=-\\sum_{i=1}^{k}\\bigl(\\sum_{j\\in \\mathcal q(i)}f(x_j)-d_i*log\\sum_{j\\in \\mathcal R(i)}e^{f(x_j)}\\bigr) \\\\\n",
    "k = \\big|\\text{unique}(\\{T_i|E_i=1\\})\\big| \\\\\n",
    "\\mathcal R(i)=\\{j|T_j\\ge T_i\\} \\\\\n",
    "\\mathcal q(i)=\\{j|T_j=T_i, E_i=1\\} \\\\\n",
    "d_i = \\vert q(i) \\vert\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step0 - Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'xgboost' was built under R version 3.5.1\"Warning message:\n",
      "\"package 'gbm' was built under R version 3.5.1\"Loaded gbm 2.1.4\n"
     ]
    }
   ],
   "source": [
    "library('survival')\n",
    "library('xgboost')\n",
    "library('gbm')\n",
    "# set random state\n",
    "set.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 137 \n",
      "Columns of dataset: trt celltype time status karno diagtime age prior \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>trt</th><th scope=col>celltype</th><th scope=col>time</th><th scope=col>status</th><th scope=col>karno</th><th scope=col>diagtime</th><th scope=col>age</th><th scope=col>prior</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1  </td><td>1  </td><td> 72</td><td>1  </td><td>60 </td><td> 7 </td><td>69 </td><td> 0 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>411</td><td>1  </td><td>70 </td><td> 5 </td><td>64 </td><td>10 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>228</td><td>1  </td><td>60 </td><td> 3 </td><td>38 </td><td> 0 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>126</td><td>1  </td><td>60 </td><td> 9 </td><td>63 </td><td>10 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>118</td><td>1  </td><td>70 </td><td>11 </td><td>65 </td><td>10 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " trt & celltype & time & status & karno & diagtime & age & prior\\\\\n",
       "\\hline\n",
       "\t 1   & 1   &  72 & 1   & 60  &  7  & 69  &  0 \\\\\n",
       "\t 1   & 1   & 411 & 1   & 70  &  5  & 64  & 10 \\\\\n",
       "\t 1   & 1   & 228 & 1   & 60  &  3  & 38  &  0 \\\\\n",
       "\t 1   & 1   & 126 & 1   & 60  &  9  & 63  & 10 \\\\\n",
       "\t 1   & 1   & 118 & 1   & 70  & 11  & 65  & 10 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "trt | celltype | time | status | karno | diagtime | age | prior | \n",
       "|---|---|---|---|---|\n",
       "| 1   | 1   |  72 | 1   | 60  |  7  | 69  |  0  | \n",
       "| 1   | 1   | 411 | 1   | 70  |  5  | 64  | 10  | \n",
       "| 1   | 1   | 228 | 1   | 60  |  3  | 38  |  0  | \n",
       "| 1   | 1   | 126 | 1   | 60  |  9  | 63  | 10  | \n",
       "| 1   | 1   | 118 | 1   | 70  | 11  | 65  | 10  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  trt celltype time status karno diagtime age prior\n",
       "1 1   1         72  1      60     7       69   0   \n",
       "2 1   1        411  1      70     5       64  10   \n",
       "3 1   1        228  1      60     3       38   0   \n",
       "4 1   1        126  1      60     9       63  10   \n",
       "5 1   1        118  1      70    11       65  10   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(veteran, package = \"randomForestSRC\")\n",
    "cat(\"Number of samples:\", nrow(veteran), \"\\n\")\n",
    "cat(\"Columns of dataset:\", colnames(veteran), \"\\n\")\n",
    "veteran[c(1:5), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x_cols <- c('trt', 'celltype', 'karno', 'diagtime', 'age', 'prior')\n",
    "y_cols <- c('T')\n",
    "# Sample the data and create a training subset.\n",
    "train <- sample(1:nrow(veteran), round(nrow(veteran) * 0.80))\n",
    "data_train <- veteran[train, ]\n",
    "data_test <- veteran[-train, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: format convertion\n",
    "\n",
    "Data applied in survival analysis from package `xgboost` should be preproceed like that **new time label with sign** indicates censored or not(*negative values are considered right censored*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column indicates time label with sign\n",
    "data_train$T <- data_train$time\n",
    "data_train$T[data_train$status==0] = -data_train$T[data_train$status==0]\n",
    "data_test$T <- data_test$time\n",
    "data_test$T[data_test$status==0] = -data_test$T[data_test$status==0]\n",
    "# Convert to xgb.DMatrix\n",
    "dtrain <- xgb.DMatrix(as.matrix(data_train[x_cols]), label=data_train[, y_cols])\n",
    "dtest  <- xgb.DMatrix(as.matrix(data_test[x_cols]), label=data_test[, y_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 - Model Selection\n",
    "\n",
    "The hyperparameters list as follows:\n",
    "- eta : learning rate\n",
    "- nrounds : number of iterations\n",
    "- max_depth : maximum depth of a tree\n",
    "- min_child_weight: minimum sum of instance weight(hessian) needed in a child\n",
    "- subsample: subsample ratio of the training instance\n",
    "- colsample_bytree: subsample ratio of columns when constructing each tree\n",
    "- gamma: minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "- alpha: L1-Regularization of instance weight items\n",
    "- labmda: L2-Regularization of instance weight items\n",
    "\n",
    "Optional Reading: You can try to search the best hyperparameters' estimation by using python package `hyperopt`.\n",
    "\n",
    "By the means of described, only `eta`, `max_depth` and `nrounds` were tuned, and repeated 4-fold cross validation on training set for 3 times is used, results of searching are:\n",
    "- \"eta\": 0.035\n",
    "- \"max_depth\": 1\n",
    "- \"nrounds\": 90\n",
    "- `CI` = 0.724952(average on repeated 4-fold cross validation for 3 times)\n",
    "\n",
    "It's interesting that `CI` on test set is only about 0.65 by using hyperparameters searched by 4-cross validation. \n",
    "\n",
    "I think the main reason is that:\n",
    "- Samples is not enough\n",
    "- The randomized test set may be different from the training set distribution.\n",
    "\n",
    "**Actually, the metrics on repeated k-fold cross validation is the best estimation of model's performance,** so using `CI` on k-fold cross validation to estimate performance and not spliting test set on small dataset is the best choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 - Model Training & Evaluation\n",
    "\n",
    "We will pass arguments to object `xgboost` for training robust model after completing hyperparameters tuning in step2, and then validate our fitted model using test set.\n",
    "\n",
    "Here, evaluation and more in this section includes:\n",
    "\n",
    "- calculating CI metrics\n",
    "- calculating survival function on specified time\n",
    "- saving result as file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 - Model Training & Prediction\n",
    "\n",
    "Note: returns of `predict` in `xgboost` is proportional hazard scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2891)\n",
    "param <- list(max_depth=3, eta = 0.06, silent = 1, objective = \"survival:cox\", eval_metric = \"cox-nloglik\")\n",
    "model <- xgb.train(param, dtrain, nrounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.train <- log(predict(model, dtrain))\n",
    "pred.test  <- log(predict(model, dtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - CI (concordance index)\n",
    "We can get $\\text{CI}$(concordance index) by function `rcorr.cens` from package `Hmisc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>C Index</dt>\n",
       "\t\t<dd>0.846834099752388</dd>\n",
       "\t<dt>Dxy</dt>\n",
       "\t\t<dd>0.693668199504775</dd>\n",
       "\t<dt>S.D.</dt>\n",
       "\t\t<dd>0.0406263024669645</dd>\n",
       "\t<dt>n</dt>\n",
       "\t\t<dd>110</dd>\n",
       "\t<dt>missing</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>uncensored</dt>\n",
       "\t\t<dd>102</dd>\n",
       "\t<dt>Relevant Pairs</dt>\n",
       "\t\t<dd>11308</dd>\n",
       "\t<dt>Concordant</dt>\n",
       "\t\t<dd>9576</dd>\n",
       "\t<dt>Uncertain</dt>\n",
       "\t\t<dd>626</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[C Index] 0.846834099752388\n",
       "\\item[Dxy] 0.693668199504775\n",
       "\\item[S.D.] 0.0406263024669645\n",
       "\\item[n] 110\n",
       "\\item[missing] 0\n",
       "\\item[uncensored] 102\n",
       "\\item[Relevant Pairs] 11308\n",
       "\\item[Concordant] 9576\n",
       "\\item[Uncertain] 626\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "C Index\n",
       ":   0.846834099752388Dxy\n",
       ":   0.693668199504775S.D.\n",
       ":   0.0406263024669645n\n",
       ":   110missing\n",
       ":   0uncensored\n",
       ":   102Relevant Pairs\n",
       ":   11308Concordant\n",
       ":   9576Uncertain\n",
       ":   626\n",
       "\n"
      ],
      "text/plain": [
       "       C Index            Dxy           S.D.              n        missing \n",
       "  8.468341e-01   6.936682e-01   4.062630e-02   1.100000e+02   0.000000e+00 \n",
       "    uncensored Relevant Pairs     Concordant      Uncertain \n",
       "  1.020000e+02   1.130800e+04   9.576000e+03   6.260000e+02 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hmisc::rcorr.cens(-pred.train, Surv(data_train$time, data_train$status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>C Index</dt>\n",
       "\t\t<dd>0.733532934131736</dd>\n",
       "\t<dt>Dxy</dt>\n",
       "\t\t<dd>0.467065868263473</dd>\n",
       "\t<dt>S.D.</dt>\n",
       "\t\t<dd>0.138473304506912</dd>\n",
       "\t<dt>n</dt>\n",
       "\t\t<dd>27</dd>\n",
       "\t<dt>missing</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>uncensored</dt>\n",
       "\t\t<dd>26</dd>\n",
       "\t<dt>Relevant Pairs</dt>\n",
       "\t\t<dd>668</dd>\n",
       "\t<dt>Concordant</dt>\n",
       "\t\t<dd>490</dd>\n",
       "\t<dt>Uncertain</dt>\n",
       "\t\t<dd>32</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[C Index] 0.733532934131736\n",
       "\\item[Dxy] 0.467065868263473\n",
       "\\item[S.D.] 0.138473304506912\n",
       "\\item[n] 27\n",
       "\\item[missing] 0\n",
       "\\item[uncensored] 26\n",
       "\\item[Relevant Pairs] 668\n",
       "\\item[Concordant] 490\n",
       "\\item[Uncertain] 32\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "C Index\n",
       ":   0.733532934131736Dxy\n",
       ":   0.467065868263473S.D.\n",
       ":   0.138473304506912n\n",
       ":   27missing\n",
       ":   0uncensored\n",
       ":   26Relevant Pairs\n",
       ":   668Concordant\n",
       ":   490Uncertain\n",
       ":   32\n",
       "\n"
      ],
      "text/plain": [
       "       C Index            Dxy           S.D.              n        missing \n",
       "     0.7335329      0.4670659      0.1384733     27.0000000      0.0000000 \n",
       "    uncensored Relevant Pairs     Concordant      Uncertain \n",
       "    26.0000000    668.0000000    490.0000000     32.0000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hmisc::rcorr.cens(-pred.test, Surv(data_test$time, data_test$status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 - Survival function\n",
    "\n",
    "Since `xgboost` don't have any funtion to obtain estimation of survival function, but `gbm` offers method `basehaz.gbm` to estimate the cumulative baseline hazard function $\\int_0^{t}\\lambda(z)dz$.  \n",
    "\n",
    "Survival function can be estimated by:\n",
    "$$\n",
    "s(t|X)=exp{\\{-\\ e^{f(X)}\\int_0^{t}\\lambda(z)dz\\}}\n",
    "$$\n",
    "\n",
    "**Note**: $f(X)$ is prediction of `xgboost`, which is **hazard proportion scale**.\n",
    "\n",
    "So we can get survival function of individuals easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Sepecify time of interest\n",
    "time.interest <- sort(unique(data_train$time[data_train$status==1]))\n",
    "# Estimate the cumulative baseline hazard function using training data\n",
    "basehaz.cum <- basehaz.gbm(data_train$time, data_train$status, pred.train, t.eval = time.interest, cumulative = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For individual $i$ in test set, estimation of survival function is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 9.941249e-01 9.909250e-01 9.876193e-01 9.774264e-01 9.627323e-01\n",
      " [6] 9.544953e-01 9.500786e-01 9.456689e-01 9.367973e-01 9.322204e-01\n",
      "[11] 9.275311e-01 9.130317e-01 9.075706e-01 8.964105e-01 8.901834e-01\n",
      "[16] 8.774936e-01 8.642181e-01 8.567371e-01 8.491786e-01 8.332283e-01\n",
      "[21] 8.171497e-01 8.090155e-01 8.006375e-01 7.917938e-01 7.828550e-01\n",
      "[26] 7.739191e-01 7.649031e-01 7.556682e-01 7.458965e-01 7.153657e-01\n",
      "[31] 6.932754e-01 6.818516e-01 6.592597e-01 6.477907e-01 6.362904e-01\n",
      "[36] 6.239966e-01 6.115309e-01 5.986818e-01 5.726188e-01 5.582735e-01\n",
      "[41] 5.434550e-01 5.286061e-01 5.131091e-01 4.973353e-01 4.638027e-01\n",
      "[46] 4.455546e-01 4.271471e-01 4.088866e-01 3.905505e-01 3.556362e-01\n",
      "[51] 3.340557e-01 3.129866e-01 2.925983e-01 2.720004e-01 2.510277e-01\n",
      "[56] 2.309747e-01 2.106387e-01 1.901767e-01 1.700236e-01 1.507814e-01\n",
      "[61] 1.316579e-01 1.128641e-01 9.514838e-02 7.903988e-02 6.474361e-02\n",
      "[66] 5.087781e-02 3.881994e-02 2.837836e-02 1.973286e-02 1.275237e-02\n",
      "[71] 8.031828e-03 4.501883e-03 2.101596e-03 8.770874e-04 2.287149e-04\n",
      "[76] 4.387880e-05 4.029537e-06 1.230663e-07 1.238486e-10 1.524416e-21\n"
     ]
    }
   ],
   "source": [
    "surf.i <- exp(-exp(pred.test[1])*basehaz.cum)\n",
    "print(surf.i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation of survival rate of all at specified time is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Rate of all at time 15 \n",
      " [1] 0.9322204 0.9434882 0.7989306 0.8330214 0.9248614 0.9736593 0.7749758\n",
      " [8] 0.9421433 0.9079900 0.9702481 0.9657176 0.7250688 0.9587803 0.9814105\n",
      "[15] 0.9908847 0.9359309 0.6546593 0.7648386 0.8964345 0.9563480 0.9380429\n",
      "[22] 0.9523831 0.6165586 0.9108559 0.9507935 0.9206930 0.9610685\n"
     ]
    }
   ],
   "source": [
    "specif.time <- time.interest[10]\n",
    "cat(\"Survival Rate of all at time\", specif.time, \"\\n\")\n",
    "surv.rate <- exp(-exp(pred.test)*basehaz.cum[10])\n",
    "print(surv.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - Saving as file\n",
    "\n",
    "Here, we concate test data and prediction, survival rate, and then convert it to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "res_test <- data_test\n",
    "# predicted outcome for test set\n",
    "res_test$pred <- pred.test\n",
    "res_test$survival_rate <- surv.rate\n",
    "# Save data\n",
    "write.csv(res_test, file = \"result_xgb.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
